{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2aec057e",
   "metadata": {},
   "source": [
    "# SNN Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4f124e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System Version: 3.9.18 (main, Sep 11 2023, 13:30:38) [MSC v.1916 64 bit (AMD64)]\n",
      "PyTorch version 2.3.1+cu118\n",
      "Numpy version 1.26.4\n",
      "env path:  c:\\Users\\richa\\OneDrive\\Dugree\\Project\\cuda\\Scripts\\python.exe\n",
      "Using device:  cuda\n",
      "       --> 0 : NVIDIA GeForce RTX 2070\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import itertools\n",
    "# #import cv2\n",
    "# #from google.colab import files\n",
    "# import timeit\n",
    "# from os import listdir\n",
    "# import os\n",
    "# from zipfile import ZipFile\n",
    "# import gdown\n",
    "# import shutil\n",
    "\n",
    "# import snntorch as snn\n",
    "# from snntorch import spikeplot as splt\n",
    "# from snntorch import spikegen\n",
    "\n",
    "# import torchvision.transforms.functional as TF\n",
    "# from torch.utils.data import DataLoader, random_split\n",
    "# from torchvision import datasets, transforms\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import torchvision\n",
    "# from torchview import draw_graph\n",
    "# from torchvision.transforms import ToTensor\n",
    "# from torchshape import tensorshape\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.animation import FuncAnimation\n",
    "# from IPython.display import HTML\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "#-----------------------------------------------\n",
    "import sys\n",
    "import snntorch as snn\n",
    "from snntorch import spikeplot as split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "\n",
    "print('System Version:', sys.version)\n",
    "print('PyTorch version', torch.__version__)\n",
    "# print('Torchvision version', torchvision.__version__)\n",
    "print('Numpy version', np.__version__)\n",
    "# print('Pandas version', pd.__version__)\n",
    "print(\"env path: \", sys.executable) #[+]\n",
    "\n",
    "#[+] check to see if gpu is available, else use cpu\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print('Using device: ',device)\n",
    "for i in range(torch.cuda.device_count()): print('       -->',i,':', torch.cuda.get_device_name(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34edb18a",
   "metadata": {},
   "source": [
    "## DataLoading MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9bd2a728",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size= 128\n",
    "data_path= r'./data'\n",
    "dtype= torch.float\n",
    "\n",
    "# Create the transoform for MNIST dataset to make sure its 28x28, grayscale, a tensor, and vals normalized to fall between 0 and 1\n",
    "transform= transforms.Compose([\n",
    "    transforms.Resize((28,28)),\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0,), (1,)),])\n",
    "\n",
    "# Automatically downloads and splits the MNIST dataset\n",
    "mnist_train = datasets.MNIST(data_path, train= True , download=True, transform=transform)\n",
    "mnist_test = datasets.MNIST(data_path, train= False, download=True, transform=transform)\n",
    "\n",
    "#create DataLoaders\n",
    "train_loader= DataLoader(mnist_train , batch_size= batch_size, shuffle=True, drop_last=True)\n",
    "test_loader= DataLoader(mnist_test , batch_size= batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afeb1eed",
   "metadata": {},
   "source": [
    "# Construct a Fully Connected SNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bf1909b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of inputs should match number of pixels in the MNIST img\n",
    "num_inputs= 28*28  #= 784\n",
    "\n",
    "# Hidden layer is however big you want as long as it fits in your GPU\n",
    "num_hidden= 1000\n",
    "\n",
    "# One output neuron for each of the 10 MNIST digits\n",
    "num_outputs= 10\n",
    "\n",
    "# 25 time steps is a quick simulation\n",
    "num_steps= 25\n",
    "\n",
    "# Rate of decay\n",
    "beta= 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d4072903",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define Network\n",
    "class Snn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize layers before defining the forward function\n",
    "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.lif1 = snn.Leaky(beta=beta)\n",
    "\n",
    "        self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
    "        self.lif2 = snn.Leaky(beta=beta)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # init hidden states at t=0, mem is membrane potential\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        \n",
    "        # Record the final layer\n",
    "        spk2_rec = []\n",
    "        mem2_rec = []\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            cur1 = self.fc1(x)\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "\n",
    "            # store in list\n",
    "            spk2_rec.append(spk2)\n",
    "            mem2_rec.append(mem2)\n",
    "\n",
    "        # The network returns a tensor of spike recordings over time, and a tensor of membrane potential recordnigs over time\n",
    "        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)\n",
    "        \n",
    "# Load the network onto CUDA if available\n",
    "snn = Snn().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bff27f",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "648cf923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 \t Train Loss: 2.8155517578125\n",
      "Iteration: 10 \t Train Loss: 1.1944315433502197\n",
      "Iteration: 20 \t Train Loss: 0.7074097990989685\n",
      "Iteration: 30 \t Train Loss: 0.6654691100120544\n",
      "Iteration: 40 \t Train Loss: 0.6876184940338135\n",
      "Iteration: 50 \t Train Loss: 0.7761414647102356\n",
      "Iteration: 60 \t Train Loss: 0.7439694404602051\n",
      "Iteration: 70 \t Train Loss: 0.9466572403907776\n",
      "Iteration: 80 \t Train Loss: 0.7870963215827942\n",
      "Iteration: 90 \t Train Loss: 0.6423141360282898\n",
      " --> model saved\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(snn.parameters(), lr=5e-4, betas=(0.9, 0.999))\n",
    "\n",
    "# # 60000 data samples / 128 samples per batch = approx 468 iterations\n",
    "num_epochs = 1\n",
    "loss_hist = []\n",
    "test_loss_hist = []\n",
    "counter = 0\n",
    "\n",
    "# Outer training loop\n",
    "for epoch in range(num_epochs):\n",
    "    train_batch = iter(train_loader)\n",
    "\n",
    "    # Minibatch training loop: each batch will have data which is the 128 samples, and each sample will have target labels (digits 0-9), we load all into cuda\n",
    "    for data, targets in train_batch:\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        #forward pass: we set our network to train mode, and pass the data into it\n",
    "        snn.train()\n",
    "        spk_rec, mem_rec = snn(data.flatten(1))\n",
    "\n",
    "        # initialize the loss & sum over time\n",
    "        loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
    "        loss_val += loss(spk_rec.sum(0), targets)\n",
    "\n",
    "        # Gradient calculation + weight update\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Store loss history for future plotting\n",
    "        loss_hist.append(loss_val.item())\n",
    "\n",
    "        # Print train/test loss/accuracy\n",
    "        if counter % 10 == 0:\n",
    "            print(f\"Iteration: {counter} \\t Train Loss: {loss_val.item()}\")\n",
    "        counter += 1\n",
    "\n",
    "        if counter == 100:\n",
    "          torch.save(snn.state_dict(), 'snn_mdl.pth')\n",
    "          print(' --> model saved')\n",
    "          break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646a9481",
   "metadata": {},
   "source": [
    "## Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "74bc40d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_accuracy(model, dataloader):\n",
    "  with torch.no_grad():\n",
    "    model.eval()\n",
    "    running_length = 0\n",
    "    running_accuracy = 0\n",
    "\n",
    "    for data, targets in iter(dataloader):\n",
    "      data = data.to(device)\n",
    "      targets = targets.to(device)\n",
    "\n",
    "      # forward-pass\n",
    "      # spk_rec, mem_rec = model(data)\n",
    "      spk_rec, mem_rec = model(data.flatten(1))\n",
    "      \n",
    "      spike_count = spk_rec.sum(0)\n",
    "      _, max_spike = spike_count.max(1)\n",
    "\n",
    "      # correct classes for one batch\n",
    "      num_correct = (max_spike == targets).sum()\n",
    "\n",
    "      # total accuracy\n",
    "      running_length += len(targets)\n",
    "      running_accuracy += num_correct\n",
    "    \n",
    "    accuracy = (running_accuracy / running_length)\n",
    "\n",
    "    return accuracy.item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6ccc38e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8388421535491943\n"
     ]
    }
   ],
   "source": [
    "print( 'Accuracy: ', measure_accuracy(snn, test_loader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
